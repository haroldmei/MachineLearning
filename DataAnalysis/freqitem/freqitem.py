"""
The attached dataset contains two columns. First column is the topic of a post. Second column is the
text from the post. Using the given dataset, please write a native implementation for an algorithm to
discover the frequent text item-sets from the second column. Do not use any existing function or
library to achieve this objective (develop the algorithm code for frequent itemset mining and apply on
the dataset - do not use any brute force technique). (Apriori, Eclat, or FP-growth, etc)


Simply apriofi implementation to find frequent items.
Read the second column from machine_learning_challenge.xlsx as input, give a support percentage, generate all the frequent items.

To run the program, simply copy 'machine_learning_challenge.xslx' to the same folder as freqitem.py and run:
python freqitem.py <support> <file.xslx>
This will print frequent items of a given support (a percentage such as 0.2). 
By default the program uses 0.3 support and machine_learning_challenge.xslx as input.
"""

import sys
import xlrd
from collections import defaultdict

def validateItems(candidates, corpus, minNum, freqItemDict):
    """
    get valid frequent items from potential candidates generated by 'genSet'
    """
    items = set()
    itemDict = defaultdict(int)
    # Count each of the candidates
    for item in candidates:
        for descr in corpus:
            if item.issubset(descr):
                itemDict[item] += 1

    # record the frequent item in the dict
    for item, count in itemDict.items():
        if count >= minNum:
            items.add(item)
            freqItemDict[item] = count 
    
    return items


def generateItems(tuples, singles):
    """
    generate potential k+1 tuples from k tuples, remove invalid ones early
    """
    newTuples = set()
    for curTuple in tuples:
        for a in singles:
            theItem = list(a)[0]
            if not theItem in curTuple:
                cur = list(curTuple)
                for i in range(len(curTuple)):
                    # check if this is potentially a candidate
                    cur[i] = theItem
                    if set(cur) in tuples:
                        newTuples.add(curTuple.union(a))
    return newTuples

def apriori(minFrac, itemSet, corpusSet):
    """
    apriori implementation, refer to http://web.stanford.edu/class/cs246/slides/02-assocrules.pdf
    """
    totalNum = len(corpusSet)
    minNum = totalNum * minFrac

    freqDict = defaultdict(int)  # frequent items and it's occurrence
    singles = validateItems(itemSet, corpusSet, minNum, freqDict)
    tuples = singles
    k = 1
    while tuples != set([]):
        k = k + 1
        print('generating %d-tuple items' % k)
        tuples = generateItems(tuples, singles)
        tuples = validateItems(tuples, corpusSet, minNum, freqDict)

    output = []
    for k in freqDict.keys():
        output.append([tuple(k), float(freqDict[k])/totalNum])

    return output

def load_data(fname, column):
    """
    read the column of an xlsx spreadsheet
    """
    workbook = xlrd.open_workbook(fname, "rb")
    sheets = workbook.sheet_names()
    copusSet = set()
    itemSet = set()
    for sheet_name in sheets:
        sh = workbook.sheet_by_name(sheet_name)
        for rownum in range(sh.nrows):
            row_valaues = sh.row_values(rownum)
            curSet = frozenset(row_valaues[column].split(' '))
            copusSet.add(curSet)

            # Generate 1-tuples
            for item in curSet:
                itemSet.add(frozenset([item]))
    return itemSet, copusSet

if __name__ == "__main__":
    """
    two parameters, a support percentage, and a input spreadsheet
    """
    minFrac = 0.3
    fname = 'machine_learning_challenge.xls'
    if len(sys.argv) > 1:
        minFrac = float(sys.argv[1])

    if len(sys.argv) > 2:
        fname = sys.argv[2]

    itemSet, corpusSet = load_data(fname, 1) 
    items = apriori(minFrac, itemSet, corpusSet)

    # print from longest to shortest sets
    for item, support in sorted(items, key=lambda args: args[1]):
        print ("%s , %.3f" % (str(item), support))