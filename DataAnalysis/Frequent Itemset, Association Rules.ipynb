{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Market-basket model\n",
    "* Identify items bought by sufficient many customers.\n",
    "* If someone buys diaper and milk, he is likely to by beer. \n",
    "* Beers can be found near by.\n",
    "* Discover association rules: people who bought {X,Y,Z} tend to buy {V,W}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Terminologies\n",
    "1. Confidence of an association rule: conf(I->j)=support(I+j)/support(I)\n",
    "* Support and support threshold s\n",
    "* Interestingness of an association rule: interest(I->j)= abs(conf(I->j)-p(j)).\n",
    "* Think of word 'the' in a document, although a rule (I->'the') has high confidence, it's not an interesting rule.\n",
    "* A-Priori\n",
    "* PCY\n",
    "* Maximal frequent itemsets\n",
    "* Closed itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Finding association rules\n",
    "Find all association rules with at least support s, and confidence c.\n",
    "1. Find all frequent itemsets I\n",
    "* For each subset A in I, add rule A -> (I - A)\n",
    "* Single pass to compute the confidence\n",
    "* Output rules with confidence above c\n",
    "* Post process to reduce the number of rules.\n",
    " * Maximal frequent itemsets: no immediate superset is frequent\n",
    " * Closed itemsets: no immediate superset is with the same support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Computation model\n",
    "1. Expand baskets into pairs, triples, ..., k-grams, use k nested loops to generate all sets of size k.\n",
    "* The cost of mining is usually the number of disk I/Os\n",
    "* Measure the cost by number of passes over the data\n",
    "* Generate all itemsets, but only keep track of those frequent ones\n",
    "    * Naive way is to have 2 nested loop to generate all pairs, fails if $n^2$ exceeds main memory. (Trianglar matrix)\n",
    "    * Keep a table of triples for cooccurance count [i,j,c]. (Triples. Still fails for large amount of pairs)\n",
    "    * A-Priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. A-Priori\n",
    "1. Monotonicity of \"Frequent\"\n",
    "    * If a set of items I appears at least s times, so does every subset J of I\n",
    "    * If itemset I does not appear in s baskets, so does every superset J of I\n",
    "2. Candidate Pairs\n",
    "3. Extension of Larger Itemsets\n",
    "4. A-Priori\n",
    "    * Pass 1, read basket and count each individual item, keep frequent items only\n",
    "    * Pass 2, read basket again and count pairs, keep those that are frequent only\n",
    "    * Use trianglar matrix with n number of f.i.\n",
    "    * Re-number f.i. and keep a table mapping original numbering to the new numbering.\n",
    "    * From frequent items and frequent pairs to frequent triples and so on. \n",
    "        * For each k, construct two sets of k-tuples: $C_k$ and $L_k$, denote a candidate and a true frequent k-tuple. (How to identify a $C_k$ in an efficient way?)\n",
    "        * One pass for each size k\n",
    "        * Possible extensions:\n",
    "            * Association rules with intervals: Man over 65 have 2 cars\n",
    "            * Taxonomy rules: (Bread, Butter -> FruitJam), (BakeGoods,MilkProduct -> PreservedGoods)\n",
    "            * Lower s as itemsets get bigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. PCY Algorithm\n",
    "1. Improvement to A-Priori\n",
    "2. Exploits empty memory on first pass\n",
    "    * Use idle memory in first pass to reduce memory required in pass 2.\n",
    "    * Maintain a hash table, keep a count for each bucket hashed by a pair\n",
    "    * Count pairs that are above s in the hash table. (Why is this needed?)\n",
    "    * Replace the buckets by a bit-vector called a frequent bucket\n",
    "    * Count pairs that are: 1, both i,j are frequent items; 2, {i,j} hashes to a bucket whose bit vector is 1.\n",
    "3. Frequent buckets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Frequent Itemsets in $\\le 2$ passes\n",
    "1. Simple Algorithm\n",
    "    * Ramdom sample the market-basket, run A-Priori or one of its extension, reduce s proportionally to match the sample size.\n",
    "    * Optionally verify that the candidate pairs are truely frequent (avoid false positive) in a second pass\n",
    "    * Cannot handle false-negative\n",
    "    * Use a smaller s to reduce false-negative, but require more space\n",
    "2. Savasere-Omiecinski-Navathe (SON) algorithm\n",
    "3. Toivonen's Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
