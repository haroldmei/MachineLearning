{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbb{V}$\n",
    "${\\rm I\\!D}$\n",
    "$\\Omega$\n",
    "$\\bracevert_{0}^{infty}$\n",
    "$\\overset{above}{main}$\n",
    "$\\sim$\n",
    "\n",
    "D2.1 Random variable: a mapping $ X : \\Omega \\Rightarrow \\mathbb{R} $ that assigns a real number $X(\\omega)$ to each outcome $\\omega$  \n",
    "E2.2 Flip a coin ten times. $X(\\omega)$ is the number of heads in the sequence $\\omega$ (an outcome).   \n",
    "E2.3 Let $\\Omega = {(x,y), x^2 + y^2 \\le 1}$. Draw a point 'at random' from $\\Omega$; the outcome $\\omega = (x,y)$; examples of random variables $X(\\omega)=x, Y(\\omega)=y, W(\\omega)=x+y, W(\\omega)=x^2+y^2$.  \n",
    "E2.4 Flip a coin twice and let X be the number of heads. $X(\\omega)$ takes values 0, 1 and 2; The outcome $\\omega$ is again a sequence of two head-tail combinations and there are 4 of them in the sample space $\\Omega$.   \n",
    "Let X be the random variable, x be a possible value of X, and A be a subset of the real line; define $X^{-1}(A) = {\\omega \\in \\Omega: X(\\omega) \\in A}$  \n",
    "$\\mathbb{P}(X \\in A) = \\mathbb{P}(X^{-1}(A)) = \\mathbb{P}({\\omega \\in \\Omega; X(\\omega) \\in A})$  \n",
    "$\\mathbb{P}(X = x) = \\mathbb{P}(X^{-1}(x)) = \\mathbb{P}({\\omega \\in \\Omega; X(\\omega) = x})$  \n",
    "\n",
    "D2.5 Cumulative distribution function CDF: $F_X: \\mathbb{R} \\rightarrow [0,1]$ s.t. $F_X(x) = \\mathbb{P}(X \\le x)$.  \n",
    "E2.6 Flip a fair coin twice and let X be the number of heads. $\\mathbb{P}(X=0) = \\mathbb{P}(X=2) = 1/4, \\mathbb{P}(X=1) = 1/2$. The CDF is   \n",
    "$$ \n",
    "F_X(x) = \n",
    "\\begin{cases}\n",
    "  0     & \\text{for } x < 0 \\\\\n",
    "  1/4   & \\text{for } 0\\le x < 1 \\\\\n",
    "  3/4   & \\text{for } 1\\le x < 2 \\\\\n",
    "  1     & \\text{for } x\\ge 2\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "T2.7 Let X have CDF F, Y have CDF G. If F(x) = G(x) for all x, then $\\mathbb{P}(X \\in A)=\\mathbb{P}(Y \\in A)$ for all A.  \n",
    "T2.8 $F:\\mathbb{R} \\rightarrow [0,1]$ is a CDF for some probability $\\mathbb{P}$ iff   \n",
    "1). F is non-decreasing.  \n",
    "2). $\\lim_{x \\to -\\infty} F(x)=0, \\lim_{x \\to \\infty} F(x)=1$.  \n",
    "3). F is right-continuous: $F(X)=F(X^+), where F(X^+)=\\lim_{y \\to x,y>x}F(y)$.  \n",
    "\n",
    "D2.9 PMF probability mass function for discrete r.v. X is $f_X(x)=\\mathbb{P}(X=x)$  \n",
    "D2.11 PDF probability density function for continuous r.v. X is $f_X(x)=F_X'(x)$ at all points where its CDF is differentiable.  \n",
    "\n",
    "E2.12 Given PDF for X: $f_X(x)=1 \\text{for } 0\\le x < 1$ otherwise 0, its CDF is given by\n",
    "$$ \n",
    "F_X(x) = \n",
    "\\begin{cases}\n",
    "  0     & \\text{for } x < 0 \\\\\n",
    "  x     & \\text{for } 0 \\le x le 1 \\\\\n",
    "  1     & \\text{for } x > 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "E2.13 Given PDF for X: \n",
    "$$ \n",
    "f_X(x) = \n",
    "\\begin{cases}\n",
    "  0                     & \\text{for } x < 0 \\\\\n",
    "  \\frac{1}{(1+x)^2}     & \\text{for } x >= 0\n",
    "\\end{cases}\n",
    "$$\n",
    "Since $\\int_{0}^{\\infty} \\frac{1}{(1+x)^2}dx = -\\frac{1}{1+x} \\bracevert_{0}^{\\infty} = 1$, the PDF is well defined.\n",
    "\n",
    "E2.14 Given a function for X: \n",
    "$$ \n",
    "f_X(x) = \n",
    "\\begin{cases}\n",
    "  0                 & \\text{for } x < 0 \\\\\n",
    "  \\frac{1}{1+x}     & \\text{for } x >= 0\n",
    "\\end{cases}\n",
    "$$\n",
    "Since $\\int_{0}^{\\infty} \\frac{1}{1+x}dx = log(1+x) \\bracevert_{0}^{\\infty} = \\infty$, it is not a valid PDF.\n",
    "\n",
    "L2.15 Let F be the CDF for r.m. X;  \n",
    "1). $\\mathbb{P}(X=x)=F(x)-F(x^-)$;   \n",
    "2). $\\mathbb{P}(x<X \\le y) = F(y)-F(x)$;   \n",
    "3). $\\mathbb{P}(X>x)=1-F(x)$;   \n",
    "4). If X is continuous then $F(b)-F(a)=\\mathbb{P}(a </\\le X </\\le b)$   \n",
    "\n",
    "D2.16 Inverse of CDF F: $F^{-1}(q)=inf{x:F(x)>q} \\forall q\\in [0,1]$. If F is strictly increasing and continuous, then $F^{-1}(q)$ is the unique real x s.t. F(x)=q.  \n",
    "Comments: the 'inf' definition could probably be replaced by 'sup' if we change the '>' to be '<'.   \n",
    "Terms: first quartile, median, third quartile are defined by $F^{-1}(1/4), F^{-1}(1/2)$ and $F^{-1}(3/4)$  \n",
    "equal in distribution: $X \\overset{d}{=} Y$ if $\\forall x, F_X(x)=F_Y(x) $  \n",
    "\n",
    "Important random variables  \n",
    "Point Mass: $\\mathbb{P}(X=a) = 1$  \n",
    "Discrete Uniform: $\\mathbb{P}(X)=1/k, X \\in {x_1, x_2, ..., x_k}$  \n",
    "Bernoulli: $\\mathbb{P}(X=1) = p, \\mathbb{P}(X=0) = 1-p$, the PMF can be written as $f(x)=p^x(1-p)^1-x, \\forall x \\in [0,1]$  \n",
    "Binomial: Flip coin n times, count heads. PMF takes values in {x \\in \\mathbb{R^+}, 0 \\le x \\le n}. The PMF is $f(x) = C_n^x p^x (1-p)^{n-x}, \\forall x \\in \\mathbb{R^+}, 0 \\le x \\le n$, otherwise f(x) = 0.  \n",
    "If $X_1 \\sim Binomial(n1,p), X_2 \\sim Binomial(n2,p), then X_1+X_2 \\sim Binomial(n1+n2, p)$.\n",
    "\n",
    "Geometric: $X \\sim Geom(p)$ if $\\mathbb{P}(X=k)=p(1-p)^{k-1}, k \\ge 1$. Flip coins, the probability of getting a head on the kth coin.  \n",
    "Poisson: $X \\sim Poisson(\\lambda)$ if $f(x)=e^{-\\lambda} \\frac {\\lambda^x}{x!}, x \\ge 0$. If $X1 \\sim Poisson(\\lambda1), X2 \\sim Poisson(\\lambda2)$, then $X1+X2 \\sim Poisson(\\lambda1+\\lambda2)$.  \n",
    "Continuous Uniform: $X \\sim Uniform(a,b)$ if \n",
    "$$ \n",
    "f_X(x) = \n",
    "\\begin{cases}\n",
    "  \\frac{1}{b-a}     & \\text{for } x \\in [a,b] \\\\\n",
    "  0                 & \\text{otherwise }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Normal (Gaussian):  $X \\sim N(\\mu, \\delta^2)$ if $f(x)=\\frac{1}{\\delta \\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\delta^2}}, x \\in \\mathbb{R}$  \n",
    "Useful facts:  \n",
    "1). If $X \\sim N(\\mu, \\delta^2)$, then $Z = \\frac{X-\\mu}{\\delta} \\sim N(0,1)$.  \n",
    "2). If $Z \\sim N(0,1)$, then $X = \\mu + \\delta Z \\sim N(\\mu, \\delta^2)$.  \n",
    "3). If $X_i \\sim N(\\mu_i, \\delta_i^2)$, i=1,2,...,n are independent, then $\\Sigma_{i=1}^n X_i \\sim N(\\Sigma_{i=1}^n \\mu_i, \\Sigma_{i=1}^n \\delta_i^2)$.  \n",
    "4). $\\mathbb{P}(a<X<b) = \\mathbb{P}(\\frac{a-\\mu}{\\delta}<Z<\\frac{b-\\mu}{\\delta}) = \\Phi(\\frac{b-\\mu}{\\delta}) - \\Phi(\\frac{a-\\mu}{\\delta})$.  \n",
    "\n",
    "Exponential: $X \\sim Exp(\\beta)$ if $f(x)=\\frac{1}{\\beta}e^{-x/\\beta}, x>0$. The Exponential distribution is used to model the lifetimes of electronic components and the waiting times between rare events.  \n",
    "Gamma: $X \\sim Gamma(\\alpha, \\beta)$ if $f(x)=\\frac{1}{\\beta^\\alpha \\Gamma(\\alpha)}x^{\\alpha-1}e^{-x/\\beta}, x>0$ where $\\Gamma(\\alpha)=\\int_0^{\\infty}y^{\\alpha-1}e^{-y}dy$ is called 'Gamma function'. The Exponential distribution is just a Gamma distribution with $\\alpha=1$  \n",
    "Beta: $X \\sim Beta(\\alpha,\\beta)$ if $f(x)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)+\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}, 0<x<1$.  \n",
    "t and Cauchy: $X \\sim t_\\nu$ if $f(x)=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})} \\frac{1}{(1+\\frac{x^2}{\\nu})^{(\\nu+1)/2}}$. The t distribution with degree $\\nu=\\infty$ is Normal distribution. The Cauchy distribution is a special case of t with $\\nu=1$  \n",
    "Comments: The above mentioned t-distribution pdf seems to have something missing. Should be $f(x)=\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu \\pi} \\Gamma(\\frac{\\nu}{2})} \\frac{1}{(1+\\frac{x^2}{\\nu})^{(\\nu+1)/2}}$  \n",
    "Otherwise the Cauchy distribution pdf wouldn't be $f(x)=\\frac{1}{\\pi (1+x^2)}$ by making $\\nu=1$ in t-distribution pdf.  \n",
    "\n",
    "$\\chi^2$ Distribution: X has a $\\chi^2$ Distribution with p degrees of freedom written as $X \\sim \\chi_p^2$ if $f(x)=\\frac{1}{\\Gamma(p/2) 2^{p/2}} x^{p/2-1} e^{-x/2}, x>0$.  \n",
    "If $Z_i$ with i=1,2,...,p are independent standard Normal r.v., then $\\Sigma_{i=1}^p Z_i^2 \\sim \\chi_p^2$  \n",
    "\n",
    "D2.19 PDF of joint r.v. (X,Y) is a function $f(x,y)$ where   \n",
    "1). $\\forall (x,y), f(x,y) \\ge 0$  \n",
    "2). $\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)dxdy = 1$  \n",
    "3). for any set $A \\subset \\mathbb{R} \\times \\mathbb{R}, \\mathbb{P}((X,Y) \\subset A)=\\iint_A f(x,y)dxdy$  \n",
    "Similar definition applies to discrete r.v.  \n",
    "\n",
    "D2.23 Marginal PMF of a joint discrete r.v. (X,Y) for X is defined as $f_X(x)=\\mathbb{P}(X=x)=\\sum_{y} \\mathbb{P}(X=x,Y=y)=\\sum_{y} f(x,y)$, marginal for Y is similar.  \n",
    "D2.25 Marginal PDF of a joint continuous r.v (X,Y) is similarly defined by integral  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D2.35 Conditional probability: Just remember $f_{X,Y}(x,y)=f_{X|Y}(x|y)f_Y(y)=f_{Y|X}(y|x)f_X(x)$ and $\\mathbb{P}(X,Y)=\\mathbb{P}(X) \\mathbb{P}(Y|X) = \\mathbb{P}(Y) \\mathbb{P}(X|Y)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
