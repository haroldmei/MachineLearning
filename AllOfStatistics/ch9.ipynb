{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Parametric Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametric models:\n",
    "$$\n",
    "\\mathfrak{F}=\\{ f(x; \\theta): \\theta \\in \\Theta \\}\n",
    "$$\n",
    "\n",
    "Why is nonparametric methods are preferable in statistical inference? Because we rarely know that the data is generated from a specific distribution.   \n",
    "\n",
    "Two reasons make studing parametric models useful. \n",
    "1. Some well known scenarios, such as counts of traffic accidents, follow specific models.\n",
    "2. Parametric models provide background for understanding certain nonparametric methods.\n",
    "\n",
    "Topics:  \n",
    "1. Parameters of interst\n",
    "2. Two methods: the methods of moments and method of maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Parameter of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In $X \\sim N(\\mu,\\delta^2)$, the parameter is $\\theta = (\\mu,\\delta)$. If we are only interested in $\\mu$, it can be seen as $\\mu = T(\\theta)$ and is called $\\textbf{parameter of interest}$, and $\\delta$ is called $\\textbf{nuisance parameter}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 Example  \n",
    "\n",
    "Let $X_i \\sim N(\\mu, \\delta^2)$. the parameter is $\\theta=(\\mu,\\delta)$ and the parameter space is $\\Theta={(\\mu,\\delta): \\mu \\in \\mathbb{R}, \\delta > 0}$. Suppose $X_i$ is the outcome of a blood test and suppose we are interested in $\\tau$, the fraction of the population whose test score is larger than 1. Then\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\tau=\\mathbb{P}(X>1) &=& 1-\\mathbb{P}(X<1) \\\\\n",
    "&=& 1 - \\mathbb{P}(\\frac{X-\\mu}{delta}<\\frac{1-\\mu}{\\delta}) \\\\\n",
    "&=& 1 - \\mathbb{P}(Z<\\frac{1-\\mu}{\\delta}) \\\\\n",
    "&=& 1 - \\Phi(\\frac{1-\\mu}{\\delta})\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "The parameter of interest is $\\tau=T(\\mu, \\delta)=1-\\Phi(\\frac{1-\\mu}{\\delta})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Example  \n",
    "\n",
    "Recall that $X \\sim Gamma(\\alpha,\\beta)$ if\n",
    "$$\n",
    "f(x;\\alpha,\\beta)=\\frac{1}{\\beta^\\alpha \\Gamma (\\alpha)} x^{\\alpha-1} e^{x/\\beta},x>0\n",
    "$$\n",
    "where $\\alpha,\\beta>0$ and the Gamma function is\n",
    "$$\n",
    "\\Gamma (\\alpha)=\\int_0^\\infty y^{\\alpha-1}e^{-y} dy\n",
    "$$\n",
    "The parameter $\\theta=(\\alpha,\\beta)$. It is sometimes used to model lifetimes of people, animals and electronic equipment. The mean lifetime is $T(\\alpha,\\beta)=\\mathbb{E}_\\theta (X_1)=\\alpha \\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 The Method of Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not optimal but easy to compute. Suppose that the parameter $\\theta=(\\theta_1,...,\\theta_k)$ has $k$ components. For $1\\le j \\le k$, define the jth moment\n",
    "$$\n",
    "\\alpha_j \\equiv \\alpha_j(\\theta)=\\mathbb{E}(X^j)=\\int x^j dF(x)\n",
    "$$\n",
    "and the jth sample moment\n",
    "$$\n",
    "\\hat{\\alpha}_j(\\theta)=\\frac{1}{n}\\sum_{i=1}^n X_i^j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3 Definition\n",
    "The method of momnets estimator $\\hat{\\theta}_n$ is defined to be the value of $\\theta$ such that\n",
    "$$\n",
    "\\alpha_1(\\hat{\\theta}_n)=\\hat{\\alpha}_1 \\\\\n",
    "\\alpha_2(\\hat{\\theta}_n)=\\hat{\\alpha}_2 \\\\\n",
    "... \\\\\n",
    "\\alpha_k(\\hat{\\theta}_n)=\\hat{\\alpha}_k \\\\\n",
    "$$\n",
    "there are k equations with k unknowns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.5 Example  \n",
    "\n",
    "Let $X_i \\sim N(\\mu, \\delta^2)$.  Then $\\alpha_1=\\mathbb{E}_\\theta (X_1)=\\mu, \\alpha_2=\\mathbb{E}_\\theta (X_1^2)=\\delta^2+\\mu^2$. Solve the following equations can get us $\\mu,\\delta$:\n",
    "$$\n",
    "\\begin{cases}\n",
    "  \\mu            &= \\frac{1}{n}\\sum_{i=1}^n X_i \\\\\n",
    "  \\delta^2+\\mu^2 &= \\frac{1}{n}\\sum_{i=1}^n X_i^2\n",
    "\\end{cases}\n",
    "$$\n",
    "This is a system of 2 equations with 2 unknowns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.6 Theorem\n",
    "Let $\\hat{\\theta}_n$ denote the method of moments estimator. Under appropriate conditions on the model, the following statements hold:  \n",
    "1. The estimate $\\hat{\\theta}_n$ exists with probability thending to 1.\n",
    "2. The estimate is consistent: $\\hat{\\theta}_n \\overset{P}{\\longrightarrow} \\theta$.\n",
    "3. The estimate is asympototically Normal:\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_n-\\theta) \\rightsquigarrow N(0, \\Sigma)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\Sigma = g \\mathbb{E}_\\theta (YY^T) g^T, Y=(X,X^2,...,X^k)^T, g=(g_1,g_2,...,g_k) and g_j=\\frac{\\partial a_j^{-1}(\\theta)}{\\partial \\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.7 Definition (likelihood function )\n",
    "The likelihood function is defined by \n",
    "$$\n",
    "\\mathcal{L}(\\theta)=\\prod_{i=1}^n f(X_i;\\theta)\n",
    "$$\n",
    "\n",
    "The log-likelihood function is defined by\n",
    "$$\n",
    "\\ell(\\theta)=\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^n f(X_i;\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.8 Definition (maximum likelihood estimator)\n",
    "\n",
    "The maximum likelihood estimator MLE is denoted by $\\hat{\\theta}_n$ s.t.\n",
    "$$\n",
    "\\hat{\\theta}_n = \\arg \\max \\mathcal{L}(\\theta)\n",
    "$$\n",
    "The maximum of $\\ell(\\theta)$ occurs at the same place as $\\mathcal{L}(\\theta)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.12 Example (A Hard Example)\n",
    "\n",
    "Let $X_i \\sim \\text{Uniform}(0, \\theta)$. \n",
    "$$ \n",
    "f(x;\\theta) = \n",
    "\\begin{cases}\n",
    "  \\frac{1}{\\theta} & 0 \\le x \\le \\theta \\\\\n",
    "  0                & otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Suppose $X_{(n)}=\\max{X_1,...,X_n}$, the likelihood can be written as:\n",
    "$$\n",
    "\\mathcal{L}(\\theta)=\n",
    "\\begin{cases}\n",
    "  (\\frac{1}{\\theta})^n & \\theta \\ge X_{(n)} \\\\\n",
    "  0                & \\theta \\lt X_{(n)}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Properties of MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main properties (under certain conditions) are:\n",
    "1. The MLE is consistent;\n",
    "2. The MLE is equivariant: if $\\hat{\\theta}_n$ is the MLE of \\theta, then $g(\\hat{\\theta}_n)$ is the MLE of $g(\\theta)$;\n",
    "3. The MLE is asymptotically Normal, and the estimated standard error $\\hat{se}$ can often be computed analytically;\n",
    "4. The MLE is asymptotically optimal or efficient. Roughly this means that among all well-behaved estimators, the MLE has the smallest variance, at least for large samples.\n",
    "5. The MLE is approximately the Bayes estimator.\n",
    "\n",
    "In sufficiently complicated problems these will no longer hold and the MLE will no longer be a good estimator.  \n",
    "The properties only hold if the model satifies certain regularity conditions, these are essentially smoothness conditions on $f(x;\\theta)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Consistency of MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
