{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation of a r.v.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D3.1 Expected value: \n",
    "$$ \\mathbb{E}(X)=\\int x dF(x)=\\mu=\\mu_X $$ \n",
    "is defined as following:\n",
    "$$ \n",
    "\\mathbb{E}(X) = \\int x dF(x) = \n",
    "\\begin{cases}\n",
    "  \\sum_x x f(x)     & \\text{if X is discrete } \\\\\n",
    "  \\int x f(x)dx     & \\text{if X is continuous }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "If $\\mathbb{E}(X)$ exists, then $\\int_x |x|dF(x)<\\infty$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.2 Let X ~ Bernoulli(p). \n",
    "$$\\mathbb{E}(X)=\\sum_{x=0}^1 xf(x) = 0 \\times (1-p) + 1 \\times p = p$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.3 Let X ~ Binomial(n,p) \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\mathbb{E}(X) &=& \\sum_{x=0}^n xf(x) \\\\\n",
    "&=& C_n^0 p^0 (1-p)^n + C_n^1 p^1 (1-p)^{n-1} + C_n^2 p^2 (1-p)^{n-2} + ... + C_n^n p^n (1-p)^0\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Using binomial expansion the result is $(p + 1 - p)^n = 1$. Example in the book is just a special case where n = 2 and p = .5   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.4 Let X ~ Uniform(-1,3), \n",
    "$$\n",
    "\\mathbb{E}(X) = \\int_{-1}^{3} xf(x)dx = \\int_{-1}^{3} \\frac{1}{4} xdx = 1 \n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.5 Let X ~ Cauchy. $f_X(x) = \\frac{1}{\\pi (1+x^2)}$.   \n",
    "In D3.1 we know how to check if $\\mathbb{E}(X)$ exists.   \n",
    "Let's check Cauchy distribution. When you see $\\int \\frac{1}{1+x^2}dx$, you should know that this integral is just $\\tan^{-1}(x)$.   \n",
    "Using integration by parts we have:   \n",
    "$$\n",
    "\\int |x|dF(x)=\\frac{2}{\\pi} \\int_0^{\\infty} \\frac{x}{1+x^2}dx = [x \\tan^{-1}(x)]_0^{\\infty}-\\int_0^{\\infty} \\tan^{-1}(x)dx = \\infty\n",
    "$$  \n",
    "\n",
    "Which means the expectation of Cauchy doesn't exist.   \n",
    "From $\\int \\frac{1}{1+x^2}dx$ to $\\tan^{-1}(x)$: \n",
    "$$ \n",
    "x=\\tan(v), v=\\tan^{-1}(x) \\Rightarrow \\frac{dx}{dv}=1+\\tan^2(v) = 1+x^2 \\Rightarrow \\frac{dv}{dx} = \\frac{1}{1+x^2}\n",
    "$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3.6 The Rule of the Lazy Statistician. Let Y=r(X), then \n",
    "$$ \n",
    "\\mathbb{E}(Y)=\\mathbb{E}(r(X))=\\int r(x)dF(x)\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.7 Let X ~ Unif(0,1). Let $ Y=r(X)=e^X $. Then \n",
    "$$ \n",
    "\\mathbb{E}(Y)=\\int_0^1 e^xf(x)dx=\\int_0^1e^xdx=e^x bracevert_{0}^{1} = e-1\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.8 Break a unit length stick at random and let Y be the longer piece, What is the mean of Y? If X is the break point then X ~ Unif(0,1); Y=r(X)=max{X, 1-X} hence:   \n",
    "$$\n",
    "\\mathbb{E}(Y)=\\int r(x)dF(x)=\\int_0^{1/2}(1-x)dx+\\int_{1/2}^1xdx = \\frac{3}{4}\n",
    "$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.9 Let (X,Y) have a jointly uniform distribution on the unit square, let $Z=r(X,Y)=X^2+Y^2$, then  \n",
    "$$\n",
    "\\mathbb{E}(Z) = \\iint r(x,y)dF(x,y) = \\iint_{0,0}^{1,1}(x^2+y^2)dxdy=\\int_0^1 x^2dx + \\int_0^1 y^2dy = \\frac{2}{3}\n",
    "$$  \n",
    "\n",
    "THE KTH MOMENT of X is defined to be \n",
    "$$ \n",
    "\\mathbb{E}(X^k)\n",
    "$$ \n",
    "assuming that \n",
    "$$\n",
    "\\mathbb{E}(|X|^k)<\\infty\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAMPLE MEAN & SAMPLE VARIANCE\n",
    "$$\\bar{X_n}=\\frac{1}{n}\\sum_i{X_i}$$\n",
    "$$ S_n^2=\\frac{1}{n-1} \\sum_i (X_i - \\bar{X_n})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3.17, Expectation of sample mean and sample variance. Suppose we have:\n",
    "$$ \\mathbb{E}(\\bar X_i) = \\mu $$\n",
    "$$ \\mathbb{V}(\\bar X_i) = \\delta^2 $$\n",
    "Then for the sample mean and sample variance:\n",
    "$$ \\mathbb{E}(\\bar X_n) = \\mu $$\n",
    "$$ \\mathbb{V}(\\bar X_n) = \\delta^2 / n $$\n",
    "$$ \\mathbb{E}(\\bar S_n) = \\delta^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D3.18, Covariance of different random variables\n",
    "$$ Cov(X,Y) = \\mathbb{E}((X-\\mu_X)(Y-\\mu_Y)) $$\n",
    "and the correlation:\n",
    "$$ \\rho = \\rho_{X,Y}=\\frac{Cov(X,Y)}{\\delta_X \\delta_Y} $$\n",
    "Question: the range of correlation? what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3.20 Variance of the sum of two R.V.\n",
    "$$ \\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2Cov(X,Y)$$\n",
    "\n",
    "PROOF:\n",
    "$$ \n",
    "\\begin{eqnarray*}\n",
    "\\mathbb{V}(X+Y) &=& \\mathbb{V}(X-\\mu_X + Y-\\mu_Y) \\\\\n",
    "&=& \\mathbb{E}(X-\\mu_X + Y-\\mu_Y)^2 - \\mathbb{E}^2(X-\\mu_X + Y-\\mu_Y) \\\\\n",
    "&=& \\mathbb{E}(X-\\mu_X + Y-\\mu_Y)^2 - \\mathbb{E}^2(X-\\mu_X) - \\mathbb{E}^2(Y-\\mu_Y) \\\\\n",
    "&=& \\mathbb{E}(X-\\mu_X)^2 + \\mathbb{E}(Y-\\mu_Y)^2 + 2 \\mathbb{E}((X-\\mu_X)(Y-\\mu_Y)) \\\\\n",
    "&=& \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y) \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "The last step is just by definition of Variance and Covariance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectation and Variance of Important R.V.\n",
    "| Distribution      |      Mean         |        Variance       |\n",
    "|-------------------|-------------------|-----------------------|\n",
    "|   Point mass      |         a         |           0           |\n",
    "|   Bernoulli(p)    |         p         |         p(1-p)        |\n",
    "|   Binomial(n,p)   |         np        |         np(1-p)       |\n",
    "|   Geometric(p)    |        1/p        |   $\\frac{1-p}{p^2}$   |\n",
    "| Poisson($\\lambda$)|      $\\lambda$    |  $\\lambda$            |\n",
    "|   Uniform(a,b)    |      (a+b)/2      |$\\frac{(b-a)^2}{12}$   |\n",
    "|Normal($\\mu$,$\\delta^2$)| $\\mu$        |$\\delta^2$             |\n",
    "|Exponential($\\beta$)|      $\\beta$     |$\\beta^2$              |\n",
    "|Gamma($\\alpha$,$\\beta$)|$\\alpha \\beta$|$\\alpha \\beta^2$|\n",
    "|Beta($\\alpha$,$\\beta$)|$\\frac{\\alpha}{\\alpha + \\beta}$|$\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$|\n",
    "|   $t_\\nu$         |0(if $\\nu>1$)      |$\\frac{\\nu}{\\nu-2}$ if ($\\nu>2$)|\n",
    "|   $\\chi_p^2$      |        p          |           2p          |\n",
    "|   Multinomial     |         np        |                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial variance-covariance\n",
    "$$\n",
    "\\mathbb{V}(X) = \\begin{bmatrix}\n",
    "    \\mathbb{V}(X_1) & Cov(X_1, X_2) & Cov(X_1, X_3) & \\dots  & Cov(X_1, X_k) \\\\\n",
    "    Cov(X_2, X_1) & \\mathbb{V}(X_2) & Cov(X_2, X_3) & \\dots  & Cov(X_2, X_k) \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    Cov(X_k, X_1) & Cov(X_k, X_2) & Cov(X_k, X_3) & \\dots  & \\mathbb{V}(X_k)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $X\\sim Multinomial(n,p) $\n",
    "$$\n",
    "\\mathbb{V}(X) = \\begin{bmatrix}\n",
    "    np_1(1-p_1) & -np_1 p_2 & -np_1 p_3 & \\dots  & -np_1 p_k \\\\\n",
    "    -np_2 p_1 & np_2(1-p_2) & -np_2 p_3 & \\dots  & -np_2 p_k \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    -np_k p_1 & -np_k p_2 & -np_k p_3 & \\dots  & np_k(1-p_k)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L3.21. If a is a vector and X is a random vector with mean $\\mu$ and variance $\\Sigma$, then:\n",
    "$$\n",
    "\\mathbb{E}(a^T X) = a^T \\mu \\\\\n",
    "\\mathbb{V}(a^T X) = a^T \\Sigma a\n",
    "$$\n",
    "Similar to scalor r.v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Conditional Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.23. Draw $X \\sim Unif(0,1)$, after that draw $ Y|X=x \\sim Unif(x,1) $. What is $ \\mathbb{E}(Y|X=x) $?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{eqnarray*}\n",
    "f_{Y|X=x} (y) &=& \\frac{1}{1-x} \\Rightarrow\\\\\n",
    "\\mathbb{E}(Y|X=x) &=& \\int_x^1 y \\frac{1}{1-x} dy \\\\\n",
    "&=& \\frac{1}{1-x} \\int_x^1 y  dy \\\\\n",
    "&=& \\frac{1}{1-x} (\\frac{y^2}{2}\\rvert_x^1)\\\\\n",
    "&=& \\frac{1+x}{2}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3.24 The rule of iterated Expectations:\n",
    "$$\n",
    "\\mathbb{E}(\\mathbb{E}(Y|X)) = \\mathbb{E}(Y)\n",
    "$$\n",
    "\n",
    "PROOF:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\mathbb{E}(\\mathbb{E}(Y|X)) &=& \\mathbb{E}(\\int y f(y|x) dy) \\\\\n",
    "&=& \\int (\\int y f(y|x) dy) f(x) dx \\\\\n",
    "&=& \\int \\int y f(y|x)f(x) dxdy  \\\\\n",
    "&=& \\int \\int y f(x,y) dxdy  \\\\\n",
    "&=& \\mathbb{E}(Y)\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.25. Draw $X \\sim Unif(0,1)$, after that draw $ Y|X=x \\sim Unif(x,1) $. What is $ \\mathbb{E}(Y) $?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From E3.23 we know that: \n",
    "$$\n",
    "\\mathbb{E}(Y|X=x) = \\frac{1+x}{2}\n",
    "$$  \n",
    "\n",
    "Use the rule of iterated expectations:  \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\mathbb{E}(Y) &=& \\mathbb{E}(\\mathbb{E}(Y|X)) \\\\\n",
    "&=& \\int_0^1 \\frac{1+x}{2} dx  \\\\\n",
    "&=& \\frac{3}{4} \n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T3.27 For random variables X and Y:\n",
    "$$\n",
    "\\mathbb{V}(Y) = \\mathbb{EV}(Y|X) + \\mathbb{VE}(Y|X)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROOF: use $\\mathbb{V}(X)=\\mathbb{E}(X)^2-\\mathbb{E}^2(X)$ to expand the right hand side.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\mathbb{EV}(Y|X) + \\mathbb{VE}(Y|X) &=& \n",
    "\\mathbb{E}(\\mathbb{E}(Y^2|X)-\\mathbb{E}^2(Y|X)) + \\mathbb{E}(\\mathbb{E}(Y|X))^2 - \\mathbb{E}^2(\\mathbb{E}(Y|X)) \\\\\n",
    "&=& \\mathbb{E}(Y^2) - \\mathbb{E}^2(Y|X) + \\mathbb{E}^2(Y|X) - \\mathbb{E}^2(Y) \\\\\n",
    "&=& \\mathbb{E}(Y^2) - \\mathbb{E}^2(Y)\\\\\n",
    "&=& \\mathbb{V}(Y)\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Moment Generating Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D3.29. The moment generating function MGF, or Laplace transform of X is defined by:\n",
    "\n",
    "$$\n",
    "\\psi_X(t) = \\mathbb{E}(e^{tX}) = \\int e^{tx} dF(x)\n",
    "$$\n",
    "\n",
    "where t varies over the real numbers.\n",
    "\n",
    "The 1st, 2nd, 3rd moment of X:\n",
    "$$\n",
    "\\psi_X'(t) = \\int x e^{tx} dF(x) = \\mathbb{E}(X e^{tX}), \\psi_X'(0) = \\mathbb{E}(X)\\\\\n",
    "\\psi_X''(t) = \\int x^2 e^{tx} dF(x) = \\mathbb{E}(X^2 e^{tX}), \\psi_X''(0) = \\mathbb{E}(X^2)  \\\\\n",
    "\\psi_X'''(t) = \\int x^3 e^{tx} dF(x) = \\mathbb{E}(X^3 e^{tX}), \\psi_X'''(0) = \\mathbb{E}(X^3)  \\\\\n",
    "$$\n",
    "\n",
    "THE KTH MOMENT of X is defined to be $ \\mathbb{E}(X^k) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3.30. Let $X\\sim Exp(1)$. $f(x) = \\exp(-x)$.\n",
    "$$\n",
    "\\psi_X(t) = \\mathbb{E}(e^{tX}) = \\int_0^\\infty e^{tx} e^{-x} dx = \\frac{1}{1-t} \\\\\n",
    "\\psi_X'(0) = \\mathbb{E}(X) = 1\\\\\n",
    "\\psi_X''(0) = \\mathbb{E}(X^2) = 2\\\\\n",
    "\\psi_X'''(0) = \\mathbb{E}(X^3) = 6\\\\\n",
    "\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\mathbb{E}^2(X) = 2 - 1 = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L3.31 Properties of MGF.  \n",
    "1. If $Y=aX+b$, then $\\psi_Y(t)=e^{bt}\\psi_X(at)$\n",
    "2. If $X_1, X_2, ..., X_n$ are independent and Y=\\sum_i X_i, then $\\psi_Y(t) = \\prod_i \\psi_i(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
