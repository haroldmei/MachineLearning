## topics

### Ensemble: popular ways

Bagging: Boostracp Aggregation - decrease the variance, at the cost of slightly increased bias.   
* Naive Bagging  
* Random Forest - decorrelation: at each split consider only a fration of the total feature.   

Boosting, decrease the bias. Decision stumps  
* Adaboost   
* xgboost  

### More topics
* Gaussian processes  
* HMM  
* GAN  
* representer theorem  
* kernalizing peceptron, kernalizing k-means  
* Poisson regression to predict number of visits per day  
* Unseen positive labels  
* Semi-supervised clustering  
* 
